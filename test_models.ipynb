{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"vscode\" # to be replaced by \"iframe\" if working on JULIE\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test sets for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['country', 'age', 'new_user', 'source', 'total_pages_visited'], dtype='object')\n",
      "Target variable : converted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_variable = 'converted'\n",
    "\n",
    "X = data.drop(target_variable, axis=1)\n",
    "Y = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print('Target variable :', target_variable)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['age', 'total_pages_visited']\n",
      "Found categorical features  ['new_user', 'country', 'source']\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['age', 'total_pages_visited']\n",
    "categorical_features = ['new_user', 'country', 'source']\n",
    "\n",
    "print('Found numeric features ', numeric_features)\n",
    "print('Found categorical features ', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer()), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "       country  age  new_user  source  total_pages_visited\n",
      "137434   China   19         1     Seo                    1\n",
      "112323      US   33         1  Direct                    5\n",
      "143261      US   51         1     Ads                    2\n",
      "162328   China   17         0     Seo                    1\n",
      "158039   China   28         1     Seo                    5\n",
      "...Done.\n",
      "[[-1.3990984  -1.15935344  1.          0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 0.29299544  0.03743241  1.          0.          0.          1.\n",
      "   1.          0.        ]\n",
      " [ 2.46854467 -0.86015697  1.          0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [-1.64082609 -1.15935344  0.          0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [-0.31132378  0.03743241  1.          0.          0.          0.\n",
      "   0.          1.        ]]\n",
      "\n",
      "Performing preprocessings on test set...\n",
      "       country  age  new_user  source  total_pages_visited\n",
      "138303      UK   34         1     Ads                    1\n",
      "133130      UK   32         0     Ads                    5\n",
      "245758      US   44         1     Ads                    1\n",
      "185267      US   35         1  Direct                    1\n",
      "177637      US   29         1  Direct                    3\n",
      "...Done.\n",
      "[[ 0.41385929 -1.15935344  1.          0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.1721316   0.03743241  0.          0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [ 1.62249775 -1.15935344  1.          0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [ 0.53472314 -1.15935344  1.          0.          0.          1.\n",
      "   1.          0.        ]\n",
      " [-0.19045994 -0.56096051  1.          0.          0.          1.\n",
      "   1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train.head())\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5]) \n",
    "print()\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test.head()) \n",
    "X_test = preprocessor.transform(X_test) # Don't fit again !! \n",
    "print('...Done.')\n",
    "print(X_test[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance assessment \n",
    "- f1_score, cross_val_score, confusion matrices, Feature Importance and Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(model):\n",
    "  Y_train_pred = model.predict(X_train)\n",
    "  Y_test_pred = model.predict(X_test)\n",
    "\n",
    "  # Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "  print(model.__class__.__name__)\n",
    "  print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "  print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "  print()\n",
    "  \n",
    "  scores = cross_val_score(model, X_train, Y_train, cv=5, scoring='f1')\n",
    "  print('The cross-validated f1 score is : ', scores.mean())\n",
    "  print('The standard deviation is : ', scores.std())\n",
    "  print('is this model overfitting ? ', f1_score(Y_test, Y_test_pred) - f1_score(Y_train, Y_train_pred) > scores.std())\n",
    "\n",
    "  # Visualize confusion matrices\n",
    "  _, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "  axes[0].set(title=\"Confusion Matrix on Train set\") # Set a title that we will add into ConfusionMatrixDisplay\n",
    "  ConfusionMatrixDisplay.from_estimator(model, X_train, Y_train, ax=axes[0]) # ConfusionMatrixDisplay from sklearn\n",
    "\n",
    "  axes[1].set(title=\"Confusion Matrix on Test set\") # Set a title that we will add into ConfusionMatrixDisplay\n",
    "  ConfusionMatrixDisplay.from_estimator(model, X_test, Y_test, ax=axes[1]) # ConfusionMatrixDisplay from sklearn\n",
    "  plt.show()\n",
    "\n",
    "  # Feature Importance\n",
    "  # numeric_features +  encoded categorical column names\n",
    "  columns = np.append(numeric_features, preprocessor.transformers_[1][1]['encoder'].get_feature_names_out(categorical_features))\n",
    "  try:\n",
    "    coefs = pd.DataFrame(index=columns, data=model.coef_.transpose(), columns=['coefficients'] )\n",
    "    # Compute abs() and sort values\n",
    "    feature_importance = abs(coefs).sort_values(by = 'coefficients')\n",
    "    # Plot coefficients\n",
    "    fig = px.bar(feature_importance, orientation = 'h', title='Feature Importance')\n",
    "    fig.update_layout(showlegend = False, \n",
    "                      margin = {'l': 120} # to avoid cropping of column names\n",
    "                      )\n",
    "    fig.show()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  # Classification report\n",
    "  print('classification_report on Train set')\n",
    "  print(classification_report(Y_train,Y_train_pred))\n",
    "  print('---')\n",
    "  print('classification_report on Test set')\n",
    "  print(classification_report(Y_test,Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(model):\n",
    "  Y_train_pred = model.predict(X_train)\n",
    "  Y_test_pred = model.predict(X_test)\n",
    "\n",
    "  # Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "  print(model.__class__.__name__)\n",
    "  print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "  print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Simple Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = DecisionTreeClassifier()\n",
    "model_2 = RandomForestClassifier()\n",
    "model_3 = LogisticRegression()\n",
    "model_4 = AdaBoostClassifier()\n",
    "model_5 = GradientBoostingClassifier()\n",
    "model_6 = XGBClassifier()\n",
    "model_7 = SGDClassifier()\n",
    "model_8 = KNeighborsClassifier()\n",
    "model_9 = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "f1-score on train set :  0.8026185582705335\n",
      "f1-score on test set :  0.7174641877476381\n",
      "RandomForestClassifier\n",
      "f1-score on train set :  0.8070540962869261\n",
      "f1-score on test set :  0.7336114421930869\n",
      "LogisticRegression\n",
      "f1-score on train set :  0.7654507084715104\n",
      "f1-score on test set :  0.7554347826086957\n",
      "AdaBoostClassifier\n",
      "f1-score on train set :  0.7575872247029442\n",
      "f1-score on test set :  0.7481146304675715\n",
      "GradientBoostingClassifier\n",
      "f1-score on train set :  0.7643552403229458\n",
      "f1-score on test set :  0.7508265704839194\n",
      "XGBClassifier\n",
      "f1-score on train set :  0.7772533153517645\n",
      "f1-score on test set :  0.7491778774289984\n",
      "SGDClassifier\n",
      "f1-score on train set :  0.7638541429762717\n",
      "f1-score on test set :  0.7493179751439831\n",
      "KNeighborsClassifier\n",
      "f1-score on train set :  0.7795484727755646\n",
      "f1-score on test set :  0.7341398642667454\n",
      "LGBMClassifier\n",
      "f1-score on train set :  0.773591943304737\n",
      "f1-score on test set :  0.7479964381121994\n"
     ]
    }
   ],
   "source": [
    "# Which base model fitting better with our dataset\n",
    "for model in [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9]:\n",
    "  model.fit(X_train, Y_train)\n",
    "  get_f1_score(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Models are **Logistic Regression, GradientBoosting, XGBoost and SGDClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Voting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Tree', DecisionTreeClassifier()),\n",
       "                             ('Forest', RandomForestClassifier()),\n",
       "                             ('log_reg', LogisticRegression()),\n",
       "                             ('adaboost', AdaBoostClassifier()),\n",
       "                             ('gradientboost', GradientBoostingClassifier()),\n",
       "                             ('xgboost',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_s...\n",
       "                                            learning_rate=0.300000012,\n",
       "                                            max_bin=256, max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
       "                             ('sgdc', SGDClassifier()),\n",
       "                             ('kneighbors', KNeighborsClassifier()),\n",
       "                             ('lgbm', LGBMClassifier())])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier([('Tree', model_1), ('Forest', model_2), ('log_reg', model_3), ('adaboost', model_4), ('gradientboost', model_5), ('xgboost', model_6), ('sgdc', model_7), ('kneighbors', model_8), ('lgbm', model_9)], voting='hard')\n",
    "\n",
    "voting_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier\n",
      "f1-score on train set :  0.7781009920190946\n",
      "f1-score on test set :  0.7512630014858841\n"
     ]
    }
   ],
   "source": [
    "get_f1_score(voting_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('log_reg', LogisticRegression()),\n",
       "                             ('gradientboost', GradientBoostingClassifier()),\n",
       "                             ('xgboost',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy='depthwise',\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.300000012,\n",
       "                                            max_bin=256, max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...))])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_best = VotingClassifier([('log_reg', model_3), ('gradientboost', model_5), ('xgboost', model_6)], voting='hard')\n",
    "\n",
    "voting_classifier_best.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTree (with hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 10, 'min_samples_leaf': 12, 'min_samples_split': 2}\n",
      "Best validation accuracy :  0.9856059807435519\n",
      "\n",
      "GridSearchCV\n",
      "f1-score on train set :  0.7662841073192976\n",
      "f1-score on test set :  0.7435351384240949\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [8, 10, 12], \n",
    "    'min_samples_leaf': [10, 12, 14],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "dt_opt = GridSearchCV(dt, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "dt_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", dt_opt.best_params_)\n",
    "print(\"Best validation accuracy : \", dt_opt.best_score_)\n",
    "print()\n",
    "get_f1_score(dt_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest (with hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "{'max_depth': [2, 4, 6, 8, 10], 'min_samples_leaf': [1, 2, 5], 'min_samples_split': [2, 4, 8], 'n_estimators': [10, 20, 40, 60, 80, 100]}\n",
      "Fitting 3 folds for each of 270 candidates, totalling 810 fits\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Best validation accuracy :  0.9861638203668565\n",
      "\n",
      "GridSearchCV\n",
      "f1-score on train set :  0.767815042969047\n",
      "f1-score on test set :  0.7428397318708104\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [2, 4, 6, 8, 10], \n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'n_estimators': [10, 20, 40, 60, 80, 100]\n",
    "}\n",
    "print(params)\n",
    "random_forest_opt = GridSearchCV(random_forest, param_grid = params, cv = 3, verbose = 1) \n",
    "# cv : the number of folds to be used for CV\n",
    "random_forest_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", random_forest_opt.best_params_)\n",
    "print(\"Best validation accuracy : \", random_forest_opt.best_score_)\n",
    "print()\n",
    "get_f1_score(random_forest_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "f1-score on train set :  0.7824324324324325\n",
      "f1-score on test set :  0.732810615199035\n"
     ]
    }
   ],
   "source": [
    "bagging_kneighbors = BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators = 5)\n",
    "bagging_kneighbors.fit(X_train, Y_train)\n",
    "get_f1_score(bagging_kneighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adaboost with logistic regression as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "{'base_estimator__C': [0.01, 0.05, 0.1, 0.5], 'n_estimators': [5, 10, 20, 30]}\n",
      "...Done.\n",
      "Best hyperparameters :  {'base_estimator__C': 0.5, 'n_estimators': 30}\n",
      "Best validation accuracy :  0.985092065500035\n",
      "\n",
      "GridSearchCV\n",
      "f1-score on train set :  0.7356931233432092\n",
      "f1-score on test set :  0.7215466167758028\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "logistic_regression = LogisticRegression(max_iter = 1000) # max_iter changed because of convergence warning\n",
    "adaboost_log_reg = AdaBoostClassifier(logistic_regression)\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'base_estimator__C': [0.01, 0.05, 0.1, 0.5,], # base_estimator__ prefix because C is a parameter from LogisticRegression! \n",
    "    'n_estimators': [5, 10, 20, 30] # n_estimators is a hyperparameter of the ensemble method\n",
    "}\n",
    "print(params)\n",
    "adaboost_log_reg_opt = GridSearchCV(adaboost_log_reg, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "adaboost_log_reg_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", adaboost_log_reg_opt.best_params_)\n",
    "print(\"Best validation accuracy : \", adaboost_log_reg_opt.best_score_)\n",
    "print()\n",
    "get_f1_score(adaboost_log_reg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adaboost with decision tree as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_model = AdaBoostClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "{'base_estimator__max_depth': [6, 8, 10], 'base_estimator__min_samples_leaf': [1, 2, 3], 'base_estimator__min_samples_split': [4, 8, 10], 'n_estimators': [4, 6, 8, 10]}\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "...Done.\n",
      "Best hyperparameters :  {'base_estimator__max_depth': 6, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 4, 'n_estimators': 8}\n",
      "Best validation accuracy :  0.9858827043362147\n",
      "\n",
      "GridSearchCV\n",
      "f1-score on train set :  0.7717860866974527\n",
      "f1-score on test set :  0.7472462042274486\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "adaboost_dt = AdaBoostClassifier(decision_tree)\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'base_estimator__max_depth': [8, 10, 12], # d’abord on va tester avec [ 2, 4, 6, 8, 10, 12, 14, …, 20 ]\n",
    "    # si le meilleur paramètre est 10, on va zoomer sur les valeurs autour de 10. [ 8, 10, 12 ]\n",
    "    'base_estimator__min_samples_leaf': [1, 2, 3],\n",
    "    'base_estimator__min_samples_split': [6, 8, 10],\n",
    "    'n_estimators': [2, 4, 6, 8, 10]\n",
    "}\n",
    "print(params)\n",
    "adaboost_dt_opt = GridSearchCV(adaboost_dt, param_grid = params, cv = 3, verbose = 1) # cv : the number of folds to be used for CV\n",
    "adaboost_dt_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", adaboost_dt_opt.best_params_)\n",
    "print(\"Best validation accuracy : \", adaboost_dt_opt.best_score_)\n",
    "print()\n",
    "get_f1_score(adaboost_dt_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "{'max_depth': [8, 10, 12], 'min_samples_leaf': [1, 2, 3], 'min_samples_split': [6, 8, 10], 'n_estimators': [2, 4, 6, 8, 10, 12]}\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 12}\n",
      "Best validation accuracy :  0.9853072949609952\n",
      "\n",
      "GridSearchCV\n",
      "f1-score on train set :  0.755223643441646\n",
      "f1-score on test set :  0.732092142631745\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "gradientboost = GradientBoostingClassifier()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [8, 10, 12],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [6, 8, 10],\n",
    "    'n_estimators': [2, 4, 6, 8, 10, 12]\n",
    "}\n",
    "print(params)\n",
    "gradientboost_opt = GridSearchCV(gradientboost, param_grid = params, cv = 3, verbose = 1) # cv : the number of folds to be used for CV\n",
    "gradientboost_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gradientboost_opt.best_params_)\n",
    "print(\"Best validation accuracy : \", gradientboost_opt.best_score_)\n",
    "print()\n",
    "get_f1_score(gradientboost_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "f1-score on train set :  0.7772533153517645\n",
      "f1-score on test set :  0.7491778774289984\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, Y_train)\n",
    "get_f1_score(xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "f1-score on train set :  0.7772533153517645\n",
      "f1-score on test set :  0.7491778774289984\n",
      "\n",
      "The cross-validated f1 score is :  0.7606697430773302\n",
      "The standard deviation is :  0.008626496295500321\n",
      "is this model overfitting ?  False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report on Train set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    220320\n",
      "           1       0.86      0.71      0.78      7344\n",
      "\n",
      "    accuracy                           0.99    227664\n",
      "   macro avg       0.93      0.85      0.89    227664\n",
      "weighted avg       0.99      0.99      0.99    227664\n",
      "\n",
      "---\n",
      "classification_report on Test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     55080\n",
      "           1       0.83      0.68      0.75      1836\n",
      "\n",
      "    accuracy                           0.99     56916\n",
      "   macro avg       0.91      0.84      0.87     56916\n",
      "weighted avg       0.98      0.99      0.98     56916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_performance(xgboost_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost (with hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "{'max_depth': [13, 14, 15], 'min_child_weight': [15, 20, 25], 'n_estimators': [8, 10, 12]}\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV 1/3] END max_depth=13, min_child_weight=15, n_estimators=8;, score=0.754 total time=   0.5s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=15, n_estimators=8;, score=0.767 total time=   0.5s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=15, n_estimators=8;, score=0.765 total time=   0.5s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=15, n_estimators=10;, score=0.756 total time=   0.5s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=15, n_estimators=10;, score=0.767 total time=   1.0s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=15, n_estimators=10;, score=0.766 total time=   0.6s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=15, n_estimators=12;, score=0.753 total time=   0.8s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=15, n_estimators=12;, score=0.767 total time=   0.8s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=15, n_estimators=12;, score=0.765 total time=   0.7s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=20, n_estimators=8;, score=0.754 total time=   0.4s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=20, n_estimators=8;, score=0.763 total time=   0.4s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=20, n_estimators=8;, score=0.770 total time=   0.5s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=20, n_estimators=10;, score=0.758 total time=   0.6s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=20, n_estimators=10;, score=0.764 total time=   0.5s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=20, n_estimators=10;, score=0.772 total time=   0.6s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=20, n_estimators=12;, score=0.757 total time=   0.6s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=20, n_estimators=12;, score=0.764 total time=   0.7s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=20, n_estimators=12;, score=0.770 total time=   0.6s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=25, n_estimators=8;, score=0.753 total time=   0.4s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=25, n_estimators=8;, score=0.766 total time=   0.4s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=25, n_estimators=8;, score=0.770 total time=   0.5s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=25, n_estimators=10;, score=0.753 total time=   0.6s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=25, n_estimators=10;, score=0.764 total time=   0.5s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=25, n_estimators=10;, score=0.771 total time=   0.5s\n",
      "[CV 1/3] END max_depth=13, min_child_weight=25, n_estimators=12;, score=0.754 total time=   0.6s\n",
      "[CV 2/3] END max_depth=13, min_child_weight=25, n_estimators=12;, score=0.764 total time=   0.7s\n",
      "[CV 3/3] END max_depth=13, min_child_weight=25, n_estimators=12;, score=0.771 total time=   0.6s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=15, n_estimators=8;, score=0.754 total time=   0.5s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=15, n_estimators=8;, score=0.767 total time=   0.4s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=15, n_estimators=8;, score=0.765 total time=   0.5s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=15, n_estimators=10;, score=0.756 total time=   0.6s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=15, n_estimators=10;, score=0.767 total time=   0.6s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=15, n_estimators=10;, score=0.766 total time=   0.6s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=15, n_estimators=12;, score=0.754 total time=   0.7s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=15, n_estimators=12;, score=0.767 total time=   0.8s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=15, n_estimators=12;, score=0.766 total time=   0.8s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=20, n_estimators=8;, score=0.754 total time=   0.4s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=20, n_estimators=8;, score=0.763 total time=   0.4s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=20, n_estimators=8;, score=0.770 total time=   0.4s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=20, n_estimators=10;, score=0.758 total time=   0.5s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=20, n_estimators=10;, score=0.764 total time=   0.6s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=20, n_estimators=10;, score=0.772 total time=   0.5s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=20, n_estimators=12;, score=0.757 total time=   0.6s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=20, n_estimators=12;, score=0.764 total time=   0.7s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=20, n_estimators=12;, score=0.772 total time=   0.7s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=25, n_estimators=8;, score=0.753 total time=   0.4s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=25, n_estimators=8;, score=0.766 total time=   0.4s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=25, n_estimators=8;, score=0.770 total time=   0.4s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=25, n_estimators=10;, score=0.753 total time=   0.5s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=25, n_estimators=10;, score=0.764 total time=   0.5s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=25, n_estimators=10;, score=0.771 total time=   0.6s\n",
      "[CV 1/3] END max_depth=14, min_child_weight=25, n_estimators=12;, score=0.754 total time=   0.7s\n",
      "[CV 2/3] END max_depth=14, min_child_weight=25, n_estimators=12;, score=0.764 total time=   0.6s\n",
      "[CV 3/3] END max_depth=14, min_child_weight=25, n_estimators=12;, score=0.770 total time=   0.7s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=15, n_estimators=8;, score=0.754 total time=   0.5s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=15, n_estimators=8;, score=0.767 total time=   0.5s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=15, n_estimators=8;, score=0.765 total time=   0.5s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=15, n_estimators=10;, score=0.756 total time=   0.5s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=15, n_estimators=10;, score=0.767 total time=   0.6s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=15, n_estimators=10;, score=0.766 total time=   0.6s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=15, n_estimators=12;, score=0.754 total time=   0.7s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=15, n_estimators=12;, score=0.767 total time=   0.7s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=15, n_estimators=12;, score=0.766 total time=   0.8s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=20, n_estimators=8;, score=0.754 total time=   0.6s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=20, n_estimators=8;, score=0.763 total time=   0.4s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=20, n_estimators=8;, score=0.770 total time=   0.4s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=20, n_estimators=10;, score=0.758 total time=   0.5s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=20, n_estimators=10;, score=0.764 total time=   0.5s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=20, n_estimators=10;, score=0.771 total time=   0.6s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=20, n_estimators=12;, score=0.757 total time=   0.6s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=20, n_estimators=12;, score=0.764 total time=   0.7s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=20, n_estimators=12;, score=0.772 total time=   0.7s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=25, n_estimators=8;, score=0.753 total time=   0.5s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=25, n_estimators=8;, score=0.766 total time=   0.5s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=25, n_estimators=8;, score=0.770 total time=   0.5s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=25, n_estimators=10;, score=0.753 total time=   0.7s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=25, n_estimators=10;, score=0.764 total time=   0.5s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=25, n_estimators=10;, score=0.771 total time=   0.6s\n",
      "[CV 1/3] END max_depth=15, min_child_weight=25, n_estimators=12;, score=0.754 total time=   0.7s\n",
      "[CV 2/3] END max_depth=15, min_child_weight=25, n_estimators=12;, score=0.764 total time=   0.6s\n",
      "[CV 3/3] END max_depth=15, min_child_weight=25, n_estimators=12;, score=0.770 total time=   0.6s\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 14, 'min_child_weight': 20, 'n_estimators': 10}\n",
      "Best validation accuracy :  0.7647545630972892\n",
      "\n",
      "GridSearchCV\n",
      "f1-score on train set :  0.7682358249360806\n",
      "f1-score on test set :  0.7460890493381468\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "xgboost = XGBClassifier()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [13, 14, 15],\n",
    "    'min_child_weight': [15, 20, 25],\n",
    "    'n_estimators': [8, 10, 12]\n",
    "}\n",
    "print(params)\n",
    "xgboost_opt = GridSearchCV(xgboost, param_grid = params, scoring='f1', cv = 3, verbose = 1) # cv : the number of folds to be used for CV\n",
    "xgboost_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", xgboost_opt.best_params_)\n",
    "print(\"Best validation accuracy : \", xgboost_opt.best_score_)\n",
    "print()\n",
    "get_f1_score(xgboost_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stacking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier_best = StackingClassifier([('log_reg', model_3), ('gradientboost', model_5), ('xgboost', model_6)], final_estimator=KNeighborsClassifier())\n",
    "\n",
    "stacking_classifier_best.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_and_submit(model, version=1):\n",
    "  print(model)\n",
    "  # Concatenate our train and test set to train your best classifier on all data with labels\n",
    "  X = np.append(X_train,X_test,axis=0)\n",
    "  Y = np.append(Y_train,Y_test)\n",
    "\n",
    "  model.fit(X,Y)\n",
    "\n",
    "  # Read data without labels\n",
    "  data_without_labels = pd.read_csv('data/conversion_data_test.csv')\n",
    "  print('Prediction set (without labels) :', data_without_labels.shape)\n",
    "\n",
    "  # apply the preprocessing\n",
    "  X_without_labels = preprocessor.transform(data_without_labels)\n",
    "  data = {\n",
    "    'converted': model.predict(X_without_labels)\n",
    "  }\n",
    "\n",
    "  Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
    "  Y_predictions.to_csv(f'submissions/conversion_data_test_predictions_Alexon_V{version}.csv', index=False)\n",
    "  print('Done ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10, min_samples_leaf=12)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(dt_opt.best_estimator_, version=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=8, min_samples_leaf=5, min_samples_split=4)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(random_forest_opt.best_estimator_, version=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(base_estimator=LogisticRegression(C=0.5, max_iter=1000),\n",
      "                   n_estimators=30)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(adaboost_log_reg_opt.best_estimator_, version=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=8,\n",
      "                                                         min_samples_split=6),\n",
      "                   n_estimators=4)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(adaboost_dt_opt.best_estimator_, version=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=8, min_samples_leaf=2, min_samples_split=8,\n",
      "                           n_estimators=12)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(gradientboost_opt.best_estimator_, version=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=2,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=12, n_jobs=0,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(xgboost_opt.best_estimator_, version=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(n_estimators=100)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(adaboost_model, version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier()\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n",
      "LGBMClassifier\n",
      "f1-score on train set :  0.7719036611736634\n",
      "f1-score on test set :  0.7613941018766756\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(model_9, version=12)\n",
    "\n",
    "get_f1_score(model_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n",
      "XGBClassifier\n",
      "f1-score on train set :  0.7740918643050134\n",
      "f1-score on test set :  0.763221153846154\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(xgboost_model, version=13)\n",
    "\n",
    "get_f1_score(xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('Tree', DecisionTreeClassifier()),\n",
      "                             ('Forest', RandomForestClassifier()),\n",
      "                             ('log_reg', LogisticRegression()),\n",
      "                             ('adaboost', AdaBoostClassifier()),\n",
      "                             ('gradientboost', GradientBoostingClassifier()),\n",
      "                             ('xgboost',\n",
      "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                            callbacks=None, colsample_bylevel=1,\n",
      "                                            colsample_bynode=1,\n",
      "                                            colsample_bytree=1,\n",
      "                                            early_s...\n",
      "                                            learning_rate=0.300000012,\n",
      "                                            max_bin=256, max_cat_to_onehot=4,\n",
      "                                            max_delta_step=0, max_depth=6,\n",
      "                                            max_leaves=0, min_child_weight=1,\n",
      "                                            missing=nan,\n",
      "                                            monotone_constraints='()',\n",
      "                                            n_estimators=100, n_jobs=0,\n",
      "                                            num_parallel_tree=1,\n",
      "                                            predictor='auto', random_state=0,\n",
      "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
      "                             ('sgdc', SGDClassifier()),\n",
      "                             ('kneighbors', KNeighborsClassifier()),\n",
      "                             ('lgbm', LGBMClassifier())])\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n",
      "VotingClassifier\n",
      "f1-score on train set :  0.7736389684813754\n",
      "f1-score on test set :  0.7652383826191913\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(voting_classifier, version='14_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('log_reg', LogisticRegression()),\n",
      "                             ('gradientboost', GradientBoostingClassifier()),\n",
      "                             ('xgboost',\n",
      "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                            callbacks=None, colsample_bylevel=1,\n",
      "                                            colsample_bynode=1,\n",
      "                                            colsample_bytree=1,\n",
      "                                            early_stopping_rounds=None,\n",
      "                                            enable_categorical=False,\n",
      "                                            eval_metric=None, gamma=0,\n",
      "                                            gpu_id=-1, grow_policy='depthwise',\n",
      "                                            importance_type=None,\n",
      "                                            interaction_constraints='',\n",
      "                                            learning_rate=0.300000012,\n",
      "                                            max_bin=256, max_cat_to_onehot=4,\n",
      "                                            max_delta_step=0, max_depth=6,\n",
      "                                            max_leaves=0, min_child_weight=1,\n",
      "                                            missing=nan,\n",
      "                                            monotone_constraints='()',\n",
      "                                            n_estimators=100, n_jobs=0,\n",
      "                                            num_parallel_tree=1,\n",
      "                                            predictor='auto', random_state=0,\n",
      "                                            reg_alpha=0, reg_lambda=1, ...))])\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(voting_classifier_best, version='14_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=5)\n",
      "Prediction set (without labels) : (31620, 5)\n",
      "Done ....\n"
     ]
    }
   ],
   "source": [
    "retrain_and_submit(bagging_kneighbors, version=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "f1-score on train set :  0.7822664488341006\n",
      "f1-score on test set :  0.7696897374701671\n"
     ]
    }
   ],
   "source": [
    "get_f1_score(bagging_kneighbors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c766f7c526f554c39534ac5a6b6631b3579ceeff597e65c8c23f9bc665d77d04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
